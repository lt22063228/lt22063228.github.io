---
layout: post
title: "linux--1--内核整理一"
description: ""
category: 
tags: []
---
{% include JB/setup %}

大致浏览了*linux内核设计与实现*,把其中认为比较重要的进行整理．
这里将按照章节来．大致目录如下：

- 进程管理
- 进程调度
- 系统调用
- 内核数据结构
- 中断和中断处理
- 下半部和退后执行的任务
- 内核同步介绍
- 内核同步方法
- 定时器和时间管理
- 内存管理
- 虚拟文件系统
- 进程地址空间

#### 进程管理

进程使用结构*task_struct*(进程描述符)表示，它的定义如下
{% highlight c %}
struct task_struct {
	unsigned long state; //进程状态
    int prio; //进程优先级
    unsigned long policy; //
    struct task_struct *parent; //父进程指针
    struct list_head tasks; //用于连接的结构，将这个结构连接到双向链表中
    pid_t pid; //进程pid
}
{% endhighlight %}

每个进程在内核中拥有１页的内核栈，而内核栈末端有一个结构*thread_info*用于存储线程相关信息（线程是调度的单位，而进程是资源分配的基本单位）:
{% highlight c %}
struct thread_info {
	struct task_struct *task; //进程控制块指针
    struct exec_domain *exec_domain;
    __u32 flags;
    __u32 status;
    __u32 cpu; 
    int preempt_count; // 线程是否可抢占，非０表示不可抢占
    mm_segment_t addr_limit;
    struct restart_block restart_block;
    void *sysenter_return;
    int uaccess_err;
}
{% endhighlight %}

当前执行线程通过将栈指针的后13位置０就可以访问到该结构，进而访问到进程描述符

内核通过系统调用fork来创建新进程，新进程首先会复制大部分父进程的结构，然后在试图与父进程区别开．根据传来的参数的不同，子进程可以共享部分或全部父进程资源．
*写时复制*:大部分fork操作都会紧随一个exec操作，因此对于大部分的进程创建过程，linux的策略是与父进程共享内存空间，当其中一个进程写入某页时，才分配相应的页空间，执行写操作．
新fork的进程一般会优先被调度，以免父进程的写操作进行没必要的复制．

内核线程的创建同普通线程相同，只是所有内核线程都会共享同样的内核空间，因此只是task_struct中的很多内容是共享的，如地址空间．

由于某个进程关闭时，其子进程还会存在，内核要保证进程的家族关系，必须为那些*孤儿*寻找新的养父．
退出的进程进入僵死状态，由父进程来决定如何处置，当父进程处理完毕后将内核栈以及其中的thread_info的相关资源回收，其中task_struct由开辟该结构的slab告诉缓存回收．

#### 进程调度

进程的调度要区分两种类型的进程：**I/O密集型**与**CPU密集型**.
**I/O密集型**进程的特点是占用cpu的时间较少,更多的时候是等待I/O操作.因此,最好这种类型的进程被优先调度,这样使得I/O操作能够更早的被执行,提高系统资源的利用率.
而**CPU密集型**进程的特点是需要占用大量处理器时间,有可能造成其他的进程等待太长时间.

调度的目标是尽量的公平,公平的意思是根据进程的优先级合理的分配处理器时间
传统的方法将公平体现在两方面,一个是时间片的分配,一个是优先队列的安排.
linux采用不同的方式,每个进程拥有一个优先级,但是没有时间片的概念.
基本做法是允许每个进程运行一段时间,循环轮转,选择运行最少的进程作为下一个运行进程,而不再分配时间片给每一个进程. 
**运行最少**的意思:每个进程有一个优先级,优先级越高,运行时间增加的越慢.假设运行时间为t,系统将计算所有进程的优先级,然后根据当前进程优先级计算出出虚拟运行时间vruntime,每次调度就选vruntime最小的进程.
这是一种近乎完美的多任务调度.

系统的定时器周期性调用函数update_curr(),它计算当前进程自从上一次更新以来经过了多长时间,将时间记账入相应的数据结构(sched_entity).

调度器选择使用红黑树维护当前所有就绪线程,要调度时,选择vruntime最小的进程,也就是红黑树最左边的叶子节点.一般将最小节点缓存起来.
当一个线程加入时,vruntime被设置为最小值,同时根据情况更新left_most(下一个 待调度进程).
将新调度实体插入红黑树的过程就是在红黑树上查找一个插入点的过程,一旦往右子树走一次,说明它不是最小的,否则它就是最小的.

公平调度器CFS是对普通进程的公平调度器,还有其他的调度器如实时调度器.调度器的入口pick_next_task(struct rq *rq)会根据优先级从高到低遍历每个调度器,一般实时调度器在CFS调度器之前.

need_resched标志提示是否还要进行一次调度(即是否可以抢占),调度由函数schedule()执行,他会切换当前进程的内存空间和处理器状态.
当系统从系统调用返回用户空间时候,或者从中断处理程序返回用户空间的时候,若need_resched标志被设置,*用户抢占就会发生*.

相对的是内核抢占,内核可能会持有内核数据结构的锁,此时进行抢占是不安全的.因此,在thread_info结构中有一个preempt_count,表示占有锁的计数,当它为0时候就可以抢占.
每次释放锁,如果preempt_count为0,就会进行重新调度.

主动在内核中阻塞或者主动调用schedule的进程是受支持的,因为内核代码应该清楚自己是可以安全的被抢占的.
内核抢占一般发生在:
1.  中断处理程序正在执行,且返回内核空间之前
2.  内核代码再一次具有可抢占性的时候
3.  内核任务阻塞或者显示调用schedule时候

#### 系统调用

在进行系统调用的进程处于*进程上下文*,此时内核可以休眠并且可以被抢占.因此,新的进程同样可能使用相同的系统调用,要保证系统调用是可重入的.

#### 中断和中断处理

冲入和中断处理程序

> linux中的中断处理程序是无须重入的.当一个给定的中断处理程序正在执行的时候,相应的中断线在所有处理器上都会被屏蔽掉,以防止在同一中断线上接受另一个新的中断.通常情况下,所有其他的中断都是打开的,所有这些不同中断线上的其他中断都能被处理,但当前的中断线总是被禁止的.

共享的中断处理线

> 内核接受到一个中断后,它将依次调用在该中断线上注册的每一个处理程序.处理程序通过dev参数来判断是否是它所关注的设备产生了相应的中断信号.

中断上下文的睡眠问题

> 中断不可以睡眠,那是设计上的决策.中断被认为是一种紧急事物,一般是不可以睡眠的,睡眠就代表处理时间长.
> 首先,系统中没有中断描述符,它不仅包括堆栈,可能还有许多与硬件相关的数据
> 其次,中断是非常频繁的操作,如果中断被不断睡眠,中断信息会不断往内核栈中塞数据,会立刻造成堆栈溢出
> 最后,中断不睡眠完全可以简化内核设计

中断虽然不可以睡眠,但是可以嵌套,linux中一个中断可以嵌套另外一种不同类型的中断.

中断上下文程序的职责:
负责给硬件设备做出响应,进行必要的拷贝工作.给下半部发消息通知其进行工作.
下半部可能是在中断处理程序返回后立刻开始执行,虽然同样属于内核空间,但是一个是可以安全的睡眠的,一个却不不能.

中断可能在任何时候发生,甚至在处理下半部的代码中产生,或者在内核线程在执行时候发生.

#### 下半部和推后执行的工作

上半部主要是指中断处理程序，虽然有用，但是存在一些局限：
- 中断处理程序以异步方式执行，可能随时打断其他重要代码．为避免重要代码被打断时间太长，中断处理程序必须执行得越快越好．
- 处于中断上下文的同一处理器，同级中断甚至所有中断都会被屏蔽，影响并发度，因此必须快
- 中断处理程序直接一般直接与硬件打交道，因此还是得快
- 中断处理程序不能阻塞，限制了所能实现的功能（再次强调，不再中断上下文阻塞是设计上的决策，简化设计）

对于其他时间要求较为宽松的任务，交由下半部处理．

通常下半部在中断处理程序一返回就会马上运行，下半部的关键在于：当他们运行的时候，允许***响应所有的中断***

按照分配给下半部的任务类型，将下半部分为三类：

1. 软中断
2. tasklet
3. 工作队列

###### 软中断

软中断是编译期间静态分配的．linux中总共包含了32个软中断结构体．其中９个已经被使用．
一个软中断不会抢占另外一个软中断，唯一能够抢占软中断的是中断处理程序，不过其他软中断（甚至相同类型的软中断）可以在其他处理器上同时执行．

一个注册的软中断必须在被标记之后才会执行．这被称作*触发软中断*.通常，中断处理程序会在返回前标记它的软中断，使其在稍后被执行．待处理的软中断在下列地方被检查和执行：

- 从一个硬件中断代码处返回时
- 在ksoftirqd内核线程中
- 在显示检查和执行待处理的软中断的代码中，如网络子系统中

软中断通过软中断位图来标示是否激活软中断，这个位图是*per_cpu*的．
操作位图需要同步，其中重要的是raise_softirq，操作步骤如下：

1. local_irq_save()保存eflags寄存器的if位．此时不会有其他进程进入临界区．
2. 设置pending位图
3. 若未处于中断上下文，则wakeup_softirqd()，尝试执行所有的＇挂起＇的softirq.
4. local_irq_restore()保存eflags恢复寄存器的if位

内核有两种方式执行软中断，一种是刚才提的raise_softirq,它试图唤醒一个内核线程来执行软中断．
另外一种则是直接执行do_softirq()

内核设计的想法是：让软中断成为在**硬中断**和**内核线程**之间的一个产物．
其中，raise_softirq()接口站在**内核线程**这一端，与普通内核线程争用cpu.
而do_softirq()站在**硬中断**这一端，伴随着每次do_IRQ()都会被调用．
两个接口的中和构成了软中断．

同样的，在执行软中断前，会执行__local_bh_disable()来关闭下半部，因为下半部没必要在同一CPU上嵌套执行两次，执行完毕后调用__local_bh_enable()开启．

###### tasklet

tasklet通过软中断实现,使用两类软中断(9个中断两个):HI_SOFTIRQ和TASKLET_SOFTIRQ,唯一的区别就是优先级

tasklet的结构如下:
{% highlight c %}
struct tasklet_struct {
	struct tasklet_struct *next;
    unsigned long state;
    atomic_t count;
    void (*func) (unsigned long);
    unsigned long dat;
}
{% endhighlight %}

tasklet经过调度之后才会在相应的软中断中被调用,两个函数分别是tasklet_schedule()和tasklet_hi_schedule(),因为要处理单处理器出具结构tasklet_vec和tasklet_hi_vec,在进行调度的时候要进行同步
具体的说,就是要禁止本地中断,唤起两个类型的软中断,将软中断加到相应的链表中

多处理器中的tasklet可能会被任意一个处理器执行,执行它的处理器将其state设置成TASKLET_STATE_RUN,其他处理器就不会试图运行这个tasklet了.
这样,相同的tasklet不会在两个处理器上同时执行

###### ksoftirqd

对于软中断(和tasklet),它们被触发的频率很高(每次中断返回的时候),而且有些软中断还会自行重复触发(网络子系统就会这么做)
对于重新触发的软中断,如果系统继续执行它们.在高负载(中断到来的比较频繁)的时候,用户进程可能没法得到执行(此时的调度是不公平的);如果系统选择忽略它们,那么这些软中断会选择在下次中断返回的时候再次执行,这在系统空闲的时候不是好的选择,更好的做法是立刻执行它们.
因为我们无法预先预测系统的负载,在设计的时候,开发者选择将大量出现的软中断放在一个内核线程中(ksoftirqd),与系统线程争用cpu
这样能够根据系统的负载,进行*公平的调度*

###### 工作队列

工作队列其实就是一些内核线程,它们专门处理一些*可睡眠*的下半部任务
每个处理器默认有一个工作线程,用户可以选择自己创建相应的工作线程.

###### 下半部的同步

因为执行下半部的时候允许响应中断,中断的到来意味着系统进入*中断上下文*或者*进程上下文*,在与这些上下文代码共享数据时候要做好同步工作
单纯的禁止下半部不能保证共享数据的安全,常见的做法是:先得到一个锁然后禁止下半部的处理
禁止下半部的处理实现实际上是对相应的thread_info中的preempt_count加减

###### 软中断总结

两个原则:硬中断会打断硬中断(不同类型);硬中断会打断软中断(软中断不打断硬中断,软中断不打断软中断).所有貌似复杂的时序都是这两个的叠加.

